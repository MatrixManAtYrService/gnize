"""
# Purpose

This module implements `cog`.  It's short for cognize, which is what happens in
your mind the first time that you see a new thing.  If you see that thing a
second time, you might recognize it--which is a separate sort of thing. That's
what the `recog` command line utility is for.

Presumably, the thing you want to cognize isn't alone.  Maybe it is bundled
with ads or other malware.  Maybe it it split by a pagniation boundary.
Whatevever the extra data is, we'll call the whole thing "noise" and whatever
subset you want to cognize now (and recognize later) we'll call "signal".

`cog` will create artifacts that you (or someone else) can use to identify the
signal later on--even if it is surrounded by (or lightly corruptedby ) by
different noise.

There are two components to this:

- fingerprints (stored in ~/.gnize/fingerprints.db)
- canvasses (stored in ~/.gnize/canvasses)

The fingerprints are generated by features.py, they're a list of hashes ordered
by their appearence in the noise.  Each time you cog(nize) you create a single
canvas, which is a list of strings which together make up the signal.
Canvasses aren't a single string because the signal as found in the noise might
have noise in ths middle.  For instance, here's some noise:

    asdfsdaf45646546This is the song that never ends yes it goes on
    and on my friends some people started signing it __^%%$^%k not
    knowning what it was and they'll continue singing it forever
    just because assxccjjasoadflkasdflkjsdlj.

The cognizer has some freedom in how they extract this signal, but a reasonable
choice would be:

    ["This is the song that never ends yes it goes on and on my friends some people started signing it ",
     "not knowning what it was and they'll continue singing it forever just because"]

A recognizer of the "same" signal, couched in different noise might break it up
differently, and that might corrupt some of the fingerprints that they
calculate, but unless their corruption is severe, they're likely to reidentify
enough of the same fingerprints that they can find the original canvas (and
whatever annotations go with it).

The possibility of having several canvasses for what ammounts to the "same"
signal, and building consensus on one to treat as cannonical, is a separate
problem.  For now we just want create canvasses and query for them by fingerprints.
"""

from gnize import features, dotdir


def make_canvas(noise):

    config = dotdir.make_or_get()
    print(config.to_dict())
