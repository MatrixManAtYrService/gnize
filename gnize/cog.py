"""
# Purpose

This module implements `cog`.  It's short for cognize, which is what happens in
your mind the first time that you see a new thing.  If you see that thing a
second time, you might recognize it--which is a separate sort of thing. That's
what the `recog` command line utility is for.

Presumably, the thing you want to cognize isn't alone.  Maybe it is bundled
with ads or other malware.  Maybe it it split by a pagniation boundary.
Whatevever the extra data is, we'll call the whole thing "noise" and whatever
subset you want to cognize now (and recognize later) we'll call "signal".

`cog` will create artifacts that you (or someone else) can use to identify the
signal later on--even if it is surrounded by (or lightly corruptedby ) by
different noise.

There are two components to this:

- fingerprints (stored in ~/.gnize/fingerprints.db)
- canvasses (stored in ~/.gnize/canvasses)

The fingerprints are generated by features.py, they're a list of hashes ordered
by their appearence in the noise.  Each time you cog(nize) you create a single
canvas, which is a list of strings which together make up the signal.
Canvasses aren't a single string because the signal as found in the noise might
have noise in ths middle.  For instance, here's some noise:

    asdfsdaf45646546This is the song that never ends yes it goes on
    and on my friends some people started signing it __^%%$^%k not
    knowning what it was and they'll continue singing it forever
    just because assxccjjasoadflkasdflkjsdlj.

The cognizer has some freedom in how they extract this signal, but a reasonable
choice would be:

    ["This is the song that never ends yes it goes on and on my friends some people started signing it ",
     "not knowning what it was and they'll continue singing it forever just because"]

A recognizer of the "same" signal, couched in different noise might break it up
differently, and that might corrupt some of the fingerprints that they
calculate, but unless their corruption is severe, they're likely to reidentify
enough of the same fingerprints that they can find the original canvas (and
whatever annotations go with it).

The possibility of having several canvasses for what ammounts to the "same"
signal, and building consensus on one to treat as cannonical, is a separate
problem.  For now we just want create canvasses and query for them by fingerprints.
"""

import atexit
import sys
from dataclasses import dataclass
from datetime import datetime
from enum import Enum, auto
from pprint import pformat
from textwrap import dedent, indent
from typing import List, Union, Tuple

from intervaltree import Interval, IntervalTree
from minineedle.core import Gap
from minineedle.needle import NeedlemanWunsch
from prompt_toolkit import Application
from prompt_toolkit.buffer import Buffer
from prompt_toolkit.enums import EditingMode
from prompt_toolkit.key_binding import KeyBindings
from prompt_toolkit.layout import Layout
from prompt_toolkit.layout.containers import HSplit, VSplit, Window, WindowAlign
from prompt_toolkit.layout.controls import BufferControl, FormattedTextControl
from prompt_toolkit.widgets import Frame, HorizontalLine
from rich.console import Console

from gnize import dotdir, features


class Kind(Enum):
    "cognized noise is either..."

    signal = auto()  # user identified noise as signal
    gap = auto()  # user identified noise as noise
    error = auto()  # user modified noise, this is disallowed in cog


@dataclass
class Data:
    "Each interval of noise refers to..."

    kind: Kind
    data: Union[str, Tuple[str, str]]

    def summary(self, interval, index, cursor_start=0, cursor_stop=None):

        if cursor_stop is None:
            if cursor_start in interval:
                prefix = "(*)"
            else:
                prefix = None
        else:
            if cursor_start in interval and cursor_stop > interval:
                prefix = "(*>"
            elif cursor_start < interval and cursor_stop in interval:
                prefix = "<*)"
            elif cursor_start in interval and cursor_stop in interval:
                prefix = "(*)"
            else:
                prefix = None

        # if the cursor isn't inside the subcanvas, display the subcanvas index
        if not prefix:
            prefix = f"{index}"

        flat = " ".join(self.data.split())
        width = len(flat)
        if width > 16:
            start = flat[:8]
            end = flat[-8:]
            connector = ".."
        elif width > 8:
            midpoint = int(width / 2)
            start = flat[:midpoint]
            end = flat[midpoint:]
            connector = ".."
        else:
            start = flat
            end = ""
            connector = ""

        return prefix + f"{start}{connector}{end}"


@dataclass
class Error:
    original: str
    user_change: str

    def __hash__(self):
        return (self.original + self.user_change).__hash__()

    def __lt__(self, other):
        return (self.original + self.user_change) < other


def find_gaps(signal: str, noise: str) -> IntervalTree:
    """
    Given noise found in the wild, and a signal identified in it by
    the user, build an interval tree identifying which subsets of the
    noise align with the signal.

    If the user has made edits, mark them as errors and include the
    erroneous data in that location.
    """

    class Mode(Enum):
        match = auto()
        error = auto()
        signal_gap = auto()
        noise_gap = auto()

    intervals = IntervalTree()
    a = NeedlemanWunsch(signal, noise)
    a.align()
    sig, noise = a.get_aligned_sequences()

    def get_data(m, i, sig_noise) -> Data:
        "create a Data object for this interval based how it (mis)aligns"



        def s(the_str, i):
            "extract the indicated sequence as a string"
            return "".join(the_str[interval_start:i])
        
        try:
            print("params:", m, i)
            print("signal:", s(noise, i))
            print("noise:", s(signal, i))
        except:
            pass

        if m == Mode.match:
            data = s(sig, i)
            kind = Kind.signal
        elif m == Mode.signal_gap:
            data = s(noise, i)
            kind = Kind.gap
        elif m == Mode.noise_gap:
            data = Error("", s(sig, i))
            kind = Kind.error
        elif m == Mode.error:
            data = Error(s(noise, i), s(sig, i))
            print("ERROR:", data)
            kind = Kind.error
        else:
            raise Exception(f"unexpected mode: {oldmode}")
        return Data(kind, data)

    mode = None
    interval_start = 0
    i = 0

    for i in range(len(noise)):

        n, s = noise[i], sig[i]
        oldmode = mode
        if type(n) is Gap:
            mode = Mode.noise_gap
        elif type(s) is Gap:
            mode = Mode.signal_gap
        elif type(n) == type(s) == str:
            if n == s:
                mode = Mode.match
            else:
                mode = Mode.error
        else:
            raise Exception(f"alignment issue at idx:{i} noise:{n}, signal:{s}")

        print("mode:", mode, n, s)
        if (not oldmode) or (oldmode == mode):
            continue
        else:
            data = get_data(oldmode, i, (s, n))
            intervals[interval_start:i] = data
            interval_start = i

    data = get_data(mode, i + 1, (s, n))
    intervals[interval_start : i + 1] = data

    return intervals


@dataclass
class InterpretedEdit:
    begin: int
    end: int
    injected: str
    corrected: str


def remove_transpositions(sig_noise: IntervalTree, noise: str) -> List[InterpretedEdit]:
    """
    Deleting a character means "this is noise", adding one means
    "there is signal here".  It does NOT mean that the newly added
    character is that signal, the signal has to come out of the
    noise.

    We handle this by replacing the addition/transposition with
    data from the noise.  Mutates the given intervaltree, returns
    a list the mutations made.
    """

    changes = []
    for it in sig_noise.items():
        if it.data.kind == Kind.error:
            fixed = Data(Kind.signal, noise[it.begin : it.end])
            sig_noise[it.begin : it.end] = fixed
            changes.append(InterpretedEdit(it.begin, it.end, it.data.data, fixed.data))

    return changes


subcanvasses = []
subcanvasses_display = FormattedTextControl(text="")
gaps = []
gaps_display = FormattedTextControl(text="")
debug_display = FormattedTextControl(text="")


def update(event):
    global subcanvasses
    global subcanvasses_display
    global gaps
    global gaps_display
    global debug_display

    # align signal to noise
    sig_noise = find_gaps(buffer.text, noise)
    remove_transpositions(sig_noise, noise)
    intervals = sorted(sig_noise)
    debug(intervals)

    # show user recent changes
    subcanvasses = []
    gaps = []
    new_text = ""
    for interval in intervals:
        if interval.data.kind is Kind.error:
            raise Exception("cog doesn't edit, ")
        elif interval.data.kind is Kind.signal:
            subcanvasses.append(interval)
            new_text += interval.data.data
        elif interval.data.kind is Kind.gap:
            gaps.append(interval)
            new_text += interval.data.data
            # todo: formatting
    debug(new_text)
    buffer.text = new_text

    if event.selection_state:
        selected_from = min(
            event._Buffer__cursor_position,
            event.selection_state.original_cursor_position,
        )
        selected_to = max(
            event._Buffer__cursor_position,
            event.selection_state.original_cursor_position,
        )
        debug_display.text = f"{len(subcanvasses)} subcanvasses, {len(gaps)} gaps, selected: {selected_from}, {selected_to}"
        render(
            subcanvasses, subcanvasses_display, selected_from, cursor_stop=selected_to
        )
        render(gaps, gaps_display, selected_from, selected_to)
    else:
        cursor_position = event._Buffer__cursor_position
        debug_display.text = f"{len(subcanvasses)} subcanvasses, {len(gaps)} gaps, cursor:{cursor_position}"
        render(subcanvasses, subcanvasses_display, cursor_position)
        render(gaps, gaps_display, cursor_position)


def render(interval_list, interval_display, cursor_start, cursor_stop=None):
    interval_display.text = "\n".join(
        [
            x.data.summary(x, i, cursor_start, cursor_stop=cursor_stop)
            for i, x in enumerate(interval_list)
        ]
    )


legend_left = dedent(
    """
    Done----Ctrl+D
    Cancel--Ctrl+C
    """
).strip("\n")

legend_center = dedent(
    """
    Editor--Ctrl+E
    """
).strip("\n")

legend_right = dedent(
    """
    Signals--Ctrl+[Shift]+S
    Gaps-----Ctrl+[Shift]+G
    """
).strip("\n")


debug_file = None


def close_debug_file():
    if debug_file:
        debug_file.close()


def debug(message):
    if debug_file:
        if type(message) is not str:
            debug_file.write("----\n")
            debug_file.write(indent(pformat(message), "    "))
            debug_file.write("\n")
        else:
            debug_file.write(dedent(message).strip() + "\n")
        debug_file.flush()


atexit.register(close_debug_file)


noise = ""
signal = ""
buffer = Buffer(on_text_changed=update, on_cursor_position_changed=update)

buffer_header = FormattedTextControl(text="Delete noise until only signal remains")
subcanvasses_header = FormattedTextControl(text="Signal")
gaps_header = FormattedTextControl(text="Noise")

selected_idx = 0

root_container = None
config = dotdir.make_or_get()


def make_canvas(_noise, args):

    global noise
    global debug_file
    global root_container

    noise = _noise

    ui = [
        VSplit(
            [
                Frame(
                    title="Delete noise until only signal remains",
                    body=Window(content=BufferControl(buffer=buffer)),
                ),
                Frame(
                    title="Signals",
                    body=Window(width=15, content=subcanvasses_display),
                ),
                Frame(title="Gaps", body=Window(width=10, content=gaps_display)),
            ]
        ),
        VSplit(
            [
                Window(content=FormattedTextControl(text=legend_left)),
                Window(content=FormattedTextControl(text=legend_center)),
                Window(
                    content=FormattedTextControl(text=legend_right),
                    align=WindowAlign.RIGHT,
                ),
            ]
        ),
    ]

    if args.debug:
        debug_file = open(config.runtime.debug_log, "w")
        debug(f"cog started {datetime.now()}")
        ui.append(HorizontalLine())
        ui.append(Window(content=debug_display))

    root_container = HSplit(ui)

    subcanvasses.append(Data(Kind.signal, noise))

    # start with the input noise as the signal
    buffer.text = noise

    kb = KeyBindings()

    @kb.add("c-c")
    def done(event):
        event.app.exit()

    # https://github.com/prompt-toolkit/python-prompt-toolkit/issues/502#issuecomment-466591259
    sys.stdin = sys.stderr
    Application(
        key_bindings=kb, layout=Layout(root_container), editing_mode=EditingMode.VI
    ).run()
